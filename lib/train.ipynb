{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T21:25:13.660698Z",
     "iopub.status.busy": "2025-03-17T21:25:13.660393Z",
     "iopub.status.idle": "2025-03-17T21:25:20.237461Z",
     "shell.execute_reply": "2025-03-17T21:25:20.236693Z",
     "shell.execute_reply.started": "2025-03-17T21:25:13.660667Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import os\n",
    "os.environ[\"SM_FRAMEWORK\"] = \"tf.keras\"\n",
    "import segmentation_models as sm\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, GlobalAveragePooling2D, Conv2D, UpSampling2D, Input, Dropout, Conv2DTranspose, MaxPooling2D, Flatten, Activation\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "import albumentations as A\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, roc_auc_score\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T21:25:24.179979Z",
     "iopub.status.busy": "2025-03-17T21:25:24.179634Z",
     "iopub.status.idle": "2025-03-17T21:25:24.184240Z",
     "shell.execute_reply": "2025-03-17T21:25:24.183331Z",
     "shell.execute_reply.started": "2025-03-17T21:25:24.179953Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "image_size = (224, 224)\n",
    "batch_size = 8\n",
    "n_classes = 1\n",
    "activation = 'sigmoid'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T21:25:24.487104Z",
     "iopub.status.busy": "2025-03-17T21:25:24.486765Z",
     "iopub.status.idle": "2025-03-17T21:25:24.579808Z",
     "shell.execute_reply": "2025-03-17T21:25:24.579160Z",
     "shell.execute_reply.started": "2025-03-17T21:25:24.487078Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "all_no_cancer = glob(\"../data/0/imgs/*\")\n",
    "all_cancer = glob(\"../data/1/imgs/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T21:25:24.639365Z",
     "iopub.status.busy": "2025-03-17T21:25:24.639071Z",
     "iopub.status.idle": "2025-03-17T21:25:24.644083Z",
     "shell.execute_reply": "2025-03-17T21:25:24.643241Z",
     "shell.execute_reply.started": "2025-03-17T21:25:24.639344Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(f\"Number of cancer: {len(all_cancer)}\")\n",
    "print(f\"NUmber of no cancer: {len(all_no_cancer)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T21:25:24.802048Z",
     "iopub.status.busy": "2025-03-17T21:25:24.801735Z",
     "iopub.status.idle": "2025-03-17T21:25:24.818866Z",
     "shell.execute_reply": "2025-03-17T21:25:24.817869Z",
     "shell.execute_reply.started": "2025-03-17T21:25:24.802023Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_size = 0.8\n",
    "cancer_train_paths, cancer_test_paths = train_test_split(all_cancer, train_size=train_size, random_state=42)\n",
    "no_cancer_train_paths, no_cancer_test_paths = train_test_split(all_no_cancer, train_size=train_size, random_state=42)\n",
    "\n",
    "train_paths = cancer_train_paths + no_cancer_train_paths\n",
    "test_paths = cancer_test_paths + no_cancer_test_paths\n",
    "\n",
    "train_labels = [1] * len(cancer_train_paths) + [0] * len(no_cancer_train_paths)\n",
    "test_labels = [1] * len(cancer_test_paths) + [0] * len(no_cancer_test_paths)\n",
    "\n",
    "train_paths = np.array(train_paths)\n",
    "train_labels = np.array(train_labels)\n",
    "test_paths = np.array(test_paths)\n",
    "test_labels = np.array(test_labels)\n",
    "\n",
    "random_state = 1\n",
    "np.random.seed(random_state)\n",
    "indices = np.random.permutation(len(train_paths))\n",
    "\n",
    "train_paths = train_paths[indices]\n",
    "train_labels = train_labels[indices]\n",
    "\n",
    "k = 5\n",
    "skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "folds_train_paths = []\n",
    "folds_val_paths = []\n",
    "folds_train_labels = []\n",
    "folds_val_labels = []\n",
    "\n",
    "for fold, (train_index, val_index) in enumerate(skf.split(train_paths, train_labels)):\n",
    "    folds_train_paths.append([train_paths[i] for i in train_index])\n",
    "    folds_val_paths.append([train_paths[i] for i in val_index])\n",
    "    \n",
    "    folds_train_labels.append([train_labels[i] for i in train_index])\n",
    "    folds_val_labels.append([train_labels[i] for i in val_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T21:25:24.955417Z",
     "iopub.status.busy": "2025-03-17T21:25:24.955104Z",
     "iopub.status.idle": "2025-03-17T21:25:24.962752Z",
     "shell.execute_reply": "2025-03-17T21:25:24.961921Z",
     "shell.execute_reply.started": "2025-03-17T21:25:24.955393Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "folds_train_mask_paths = []\n",
    "folds_val_mask_paths = []\n",
    "test_mask_paths = []\n",
    "\n",
    "for fold in folds_train_paths:\n",
    "    aux = []\n",
    "    for i in fold:\n",
    "        aux.append(i.replace('imgs', 'masks'))\n",
    "    folds_train_mask_paths.append(aux)\n",
    "\n",
    "for fold in folds_val_paths:\n",
    "    aux = []\n",
    "    for i in fold:\n",
    "        aux.append(i.replace('imgs', 'masks'))\n",
    "    folds_val_mask_paths.append(aux)\n",
    "\n",
    "\n",
    "for i in test_paths:\n",
    "    test_mask_paths.append(i.replace('imgs', 'masks'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T21:25:25.099568Z",
     "iopub.status.busy": "2025-03-17T21:25:25.099254Z",
     "iopub.status.idle": "2025-03-17T21:25:25.104837Z",
     "shell.execute_reply": "2025-03-17T21:25:25.104011Z",
     "shell.execute_reply.started": "2025-03-17T21:25:25.099546Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"Number of samples (train): \", len(folds_train_mask_paths[0]))\n",
    "print(\"Number of samples (validation): \", len(folds_val_mask_paths[0]))\n",
    "print(\"Number of samples (test): \", len(test_mask_paths))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T21:25:26.612254Z",
     "iopub.status.busy": "2025-03-17T21:25:26.611939Z",
     "iopub.status.idle": "2025-03-17T21:25:26.618193Z",
     "shell.execute_reply": "2025-03-17T21:25:26.617241Z",
     "shell.execute_reply.started": "2025-03-17T21:25:26.612230Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_image(path, target_size=image_size):\n",
    "    img = np.load(path)\n",
    "    img = cv2.resize(img, target_size)\n",
    "    img = ((img - img.min()) / (img.max() - img.min())) * 255\n",
    "    img = np.stack((img,) * 3, axis=-1)\n",
    "\n",
    "    return img.astype(np.uint8)\n",
    "\n",
    "\n",
    "MASK_CONST_ZEROS = np.zeros((image_size[0], image_size[1], 1), dtype='float32')\n",
    "\n",
    "def load_mask(path, label, target_size=image_size):\n",
    "    if label == 0:\n",
    "        return MASK_CONST_ZEROS\n",
    "        \n",
    "    mask = cv2.resize(np.load(path), target_size)\n",
    "    mask = (mask > 0).astype('int32')\n",
    "    mask = mask[:,:,0]\n",
    "\n",
    "    return np.expand_dims(mask, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T21:25:26.757222Z",
     "iopub.status.busy": "2025-03-17T21:25:26.756848Z",
     "iopub.status.idle": "2025-03-17T21:25:26.766790Z",
     "shell.execute_reply": "2025-03-17T21:25:26.765767Z",
     "shell.execute_reply.started": "2025-03-17T21:25:26.757191Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    CLASSES = ['no_cancer', 'cancer']\n",
    "    \n",
    "    def __init__(\n",
    "            self, \n",
    "            images_fps, \n",
    "            masks_fps, \n",
    "            class_values, \n",
    "            augmentation=None, \n",
    "            preprocessing=None,\n",
    "    ):\n",
    "        self.images_fps = images_fps\n",
    "        self.masks_fps = masks_fps\n",
    "        self.class_values = class_values\n",
    "        \n",
    "        self.augmentation = augmentation\n",
    "        self.preprocessing = preprocessing\n",
    "    \n",
    "    def __getitem__(self, i):        \n",
    "        image = load_image(self.images_fps[i])\n",
    "        label = self.class_values[i]\n",
    "        mask = load_mask(self.masks_fps[i], label)\n",
    "        \n",
    "        if self.augmentation:\n",
    "            sample = self.augmentation(image=image, mask=mask)\n",
    "            image, mask = sample['image'], sample['mask']\n",
    "        \n",
    "        if self.preprocessing:\n",
    "            sample = self.preprocessing(image=image, mask=mask)\n",
    "            image, mask = sample['image'], sample['mask']\n",
    "\n",
    "            \n",
    "        return image, mask, float(np.max(mask))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images_fps)\n",
    "    \n",
    "    \n",
    "class Dataloder(tf.keras.utils.Sequence):\n",
    "    def __init__(self, dataset, batch_size=1, shuffle=False):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.indexes = np.arange(len(dataset))\n",
    "\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __getitem__(self, i):        \n",
    "        start = i * self.batch_size\n",
    "        stop = (i + 1) * self.batch_size\n",
    "        data = []\n",
    "        for j in range(start, stop):\n",
    "            data.append(self.dataset[j])\n",
    "        \n",
    "        batch = [np.stack(samples, axis=0) for samples in zip(*data)]\n",
    "        \n",
    "        return {'input_image': batch[0]}, {'classification_output': batch[2], 'sigmoid': batch[1]}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.indexes) // self.batch_size\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            self.indexes = np.random.permutation(self.indexes)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T21:25:28.652030Z",
     "iopub.status.busy": "2025-03-17T21:25:28.651686Z",
     "iopub.status.idle": "2025-03-17T21:25:28.659014Z",
     "shell.execute_reply": "2025-03-17T21:25:28.658208Z",
     "shell.execute_reply.started": "2025-03-17T21:25:28.651982Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def round_clip_0_1(x, **kwargs):\n",
    "    return x.round().clip(0, 1)\n",
    "\n",
    "def get_image_pattern_augmentation():\n",
    "    pattern_transform = [\n",
    "        A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1, p=0.3),\n",
    "        A.GaussianBlur(blur_limit=(3, 5), p=0.3),\n",
    "        A.CLAHE(clip_limit=2.0, tile_grid_size=(8, 8), p=0.3),\n",
    "        A.GaussNoise(var_limit=(10.0, 50.0), p=0.3),\n",
    "    ]\n",
    "    return A.Compose(pattern_transform)\n",
    "\n",
    "def get_geometric_augmentation():\n",
    "    pattern_transform = [\n",
    "        A.HorizontalFlip(p=0.3),\n",
    "        A.RandomSizedCrop(min_max_height=(int(image_size[0] * 0.5), int(image_size[0])), height=int(image_size[0]), width=int(image_size[0]), p=0.3),\n",
    "        A.Rotate(limit=30, p=0.3),\n",
    "        A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.0, rotate_limit=0, p=0.3),\n",
    "    ]\n",
    "    return A.Compose(pattern_transform)\n",
    "\n",
    "def get_training_augmentation():\n",
    "    pattern_augmentations = get_image_pattern_augmentation()\n",
    "    geometric_augmentations = get_geometric_augmentation()\n",
    "\n",
    "    return A.Compose([\n",
    "        pattern_augmentations,\n",
    "        geometric_augmentations,\n",
    "    ])\n",
    "\n",
    "def get_preprocessing(preprocessing_fn):\n",
    "    _transform = [\n",
    "        A.Lambda(image=preprocessing_fn),\n",
    "    ]\n",
    "    return A.Compose(_transform)\n",
    "\n",
    "def custom_preprocessing(image, mask):\n",
    "    return {\n",
    "        image: image/255,\n",
    "        mask: mask\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T21:25:28.934751Z",
     "iopub.status.busy": "2025-03-17T21:25:28.934422Z",
     "iopub.status.idle": "2025-03-17T21:25:28.940324Z",
     "shell.execute_reply": "2025-03-17T21:25:28.939435Z",
     "shell.execute_reply.started": "2025-03-17T21:25:28.934722Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_sets(backbone_name, FOLD_I = 0, preprocessing_function=None):\n",
    "    train_paths = folds_train_paths[FOLD_I]\n",
    "    train_mask_paths = folds_train_mask_paths[FOLD_I]\n",
    "    train_labels = folds_train_labels[FOLD_I]\n",
    "\n",
    "    val_paths = folds_val_paths[FOLD_I]\n",
    "    val_mask_paths = folds_val_mask_paths[FOLD_I]\n",
    "    val_labels = folds_val_labels[FOLD_I]\n",
    "    \n",
    "    if (preprocessing_function == None):\n",
    "        preprocessing_function = get_preprocessing(sm.get_preprocessing(backbone_name))\n",
    "\n",
    "    train_dataset = Dataset(train_paths, \n",
    "                            train_mask_paths, \n",
    "                            train_labels,\n",
    "        augmentation=get_training_augmentation(),\n",
    "        preprocessing=preprocessing_function,\n",
    "    )\n",
    "\n",
    "    valid_dataset = Dataset(val_paths, \n",
    "                            val_mask_paths, \n",
    "                            val_labels, \n",
    "        augmentation=None,\n",
    "        preprocessing=preprocessing_function,\n",
    "    )\n",
    "\n",
    "    test_dataset = Dataset(test_paths, \n",
    "                            test_mask_paths, \n",
    "                            test_labels, \n",
    "        augmentation=None,\n",
    "        preprocessing=preprocessing_function,\n",
    "    )\n",
    "    \n",
    "    train_dataloader = Dataloder(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    valid_dataloader = Dataloder(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_dataset, train_dataloader, valid_dataset, valid_dataloader, test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T21:25:33.405968Z",
     "iopub.status.busy": "2025-03-17T21:25:33.405634Z",
     "iopub.status.idle": "2025-03-17T21:25:33.412079Z",
     "shell.execute_reply": "2025-03-17T21:25:33.411085Z",
     "shell.execute_reply.started": "2025-03-17T21:25:33.405938Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# helper function for data visualization\n",
    "def visualize(**images):\n",
    "    \"\"\"PLot images in one row.\"\"\"\n",
    "    n = len(images)\n",
    "    plt.figure(figsize=(16, 5))\n",
    "    for i, (name, image) in enumerate(images.items()):\n",
    "        plt.subplot(1, n, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.title(' '.join(name.split('_')).title())\n",
    "        plt.imshow(image)\n",
    "    plt.show()\n",
    "    \n",
    "# helper function for data visualization    \n",
    "def denormalize(x):\n",
    "    \"\"\"Scale image to range 0..1 for correct plot\"\"\"\n",
    "    x_max = np.percentile(x, 98)\n",
    "    x_min = np.percentile(x, 2)    \n",
    "    x = (x - x_min) / (x_max - x_min)\n",
    "    x = x.clip(0, 1)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T21:25:33.743197Z",
     "iopub.status.busy": "2025-03-17T21:25:33.742868Z",
     "iopub.status.idle": "2025-03-17T21:25:33.752722Z",
     "shell.execute_reply": "2025-03-17T21:25:33.751637Z",
     "shell.execute_reply.started": "2025-03-17T21:25:33.743170Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def plot_some_images(model, test_dataset):\n",
    "    ids = [0, 50, 150, 250]\n",
    "\n",
    "    for i in ids:\n",
    "        image, gt_mask, label = test_dataset[i]\n",
    "        image = np.expand_dims(image, axis=0)\n",
    "        predicted = model.predict(image)\n",
    "        pr_mask = predicted[1][0]\n",
    "\n",
    "        print(\"label: \" + str(label))\n",
    "        print(\"predicted: \" + str(predicted[0]))\n",
    "\n",
    "        fig, axs = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "        axs[0].imshow(denormalize(image.squeeze()), cmap='gray')\n",
    "        axs[0].set_title('Image')\n",
    "        axs[0].axis('off')  \n",
    "\n",
    "        axs[1].imshow(gt_mask[..., 0].squeeze(), cmap='gray')\n",
    "        axs[1].set_title('Ground Truth Mask')\n",
    "        axs[1].axis('off')\n",
    "\n",
    "        cax = axs[2].imshow(pr_mask[..., 0].squeeze(), cmap='hot', vmin=0, vmax=1)\n",
    "        axs[2].set_title('Predicted Mask')\n",
    "        axs[2].axis('off')\n",
    "        fig.colorbar(cax, ax=axs[2])\n",
    "\n",
    "        bbox = axs[2].get_position()\n",
    "        axs[2].set_position([bbox.x0, bbox.y0, bbox.width * 1.5, bbox.height * 1.5])\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "def print_test_metrics(model, test_dataset):\n",
    "    test_dataloader = Dataloder(test_dataset, batch_size=len(test_dataset), shuffle=False)\n",
    "\n",
    "    data_generator = test_dataloader\n",
    "    test_preds = model.predict(data_generator[0][0]['input_image'])\n",
    "    test_true_labels = data_generator[0][1]['classification_output']\n",
    "\n",
    "    test_pred_labels = (test_preds[0] > 0.5).astype(int)\n",
    "\n",
    "    accuracy = accuracy_score(test_true_labels, test_pred_labels)\n",
    "    matriz_confusao = confusion_matrix(test_true_labels, test_pred_labels)\n",
    "    auc = roc_auc_score(test_true_labels, test_preds[0])\n",
    "\n",
    "    print(\"accuracy: \"+str(accuracy))\n",
    "    print(\"auc: \"+str(auc))\n",
    "    print(\"cm: \")\n",
    "    print(matriz_confusao)\n",
    "\n",
    "    test_true_masks = data_generator[0][1]['sigmoid']\n",
    "    test_pred_masks = test_preds[1]\n",
    "\n",
    "    print(sm.metrics.IOUScore(threshold=0.5)(test_true_masks, test_pred_masks))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T21:25:34.506767Z",
     "iopub.status.busy": "2025-03-17T21:25:34.506429Z",
     "iopub.status.idle": "2025-03-17T21:25:34.513667Z",
     "shell.execute_reply": "2025-03-17T21:25:34.512724Z",
     "shell.execute_reply.started": "2025-03-17T21:25:34.506736Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "BACKBONES_TO_TEST = [\n",
    "    {\n",
    "        'name': 'resnet152',\n",
    "        'layer': 'relu1'\n",
    "    },\n",
    "    {\n",
    "        'name': 'seresnext50',\n",
    "        'layer': 'activation_80'\n",
    "    },\n",
    "    {\n",
    "        'name': 'seresnet152',\n",
    "        'layer': 'activation_250'\n",
    "    },\n",
    "    {\n",
    "        'name': 'resnext101',\n",
    "        'layer': 'stage4_unit3_relu'\n",
    "    },\n",
    "    {\n",
    "        'name': 'seresnext101',\n",
    "        'layer': 'activation_165'\n",
    "    },\n",
    "    {\n",
    "        'name': 'senet154',\n",
    "        'layer': 'activation_252'\n",
    "    },\n",
    "    {\n",
    "        'name': 'densenet201',\n",
    "        'layer': 'relu'\n",
    "    },\n",
    "    {\n",
    "        'name': 'inceptionresnetv2',\n",
    "        'layer': 'conv_7b_ac'\n",
    "    },\n",
    "    {\n",
    "        'name': 'mobilenetv2',\n",
    "        'layer': 'out_relu'\n",
    "    },\n",
    "    {\n",
    "        'name': 'efficientnetb7',\n",
    "        'layer': 'top_activation'\n",
    "    },\n",
    "    {\n",
    "        'name': 'vgg19',\n",
    "        'layer': 'center_block2_relu'\n",
    "    }\n",
    "]\n",
    "\n",
    "def get_backbone_by_name(name):\n",
    "    for backbone in BACKBONES_TO_TEST:\n",
    "        if (backbone['name'] == name):\n",
    "            return backbone\n",
    "\n",
    "def create_model(backbone):\n",
    "    model_segmentation = sm.Unet(backbone['name'], classes=n_classes, activation=activation, input_shape=(224, 224, 3), encoder_freeze=False)\n",
    "    model_segmentation_partial = Model(inputs=model_segmentation.input, outputs=model_segmentation.get_layer(backbone['layer']).output) \n",
    "\n",
    "    x = GlobalAveragePooling2D(name=\"branch_class_1\")(model_segmentation_partial.output)    \n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    classification_output = Dense(1, activation='sigmoid', name='classification_output')(x)\n",
    "\n",
    "    multitask_model = Model(inputs=model_segmentation_partial.input, outputs=[classification_output, model_segmentation.output])\n",
    "    \n",
    "    multitask_model.layers[0]._name = 'input_image'\n",
    "    \n",
    "    return multitask_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T21:25:46.402416Z",
     "iopub.status.busy": "2025-03-17T21:25:46.402117Z",
     "iopub.status.idle": "2025-03-18T00:37:41.622729Z",
     "shell.execute_reply": "2025-03-18T00:37:41.621804Z",
     "shell.execute_reply.started": "2025-03-17T21:25:46.402392Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "historys = []\n",
    "for fold_i in range(5):\n",
    "    print(f\"============ INIT FOLD {fold_i} ===============\")\n",
    "    backbone = get_backbone_by_name('seresnext101')\n",
    "    train_dataset, train_dataloader, valid_dataset, valid_dataloader, test_dataset = get_sets(backbone['name'], fold_i)\n",
    "\n",
    "    print(f\"Range: [{np.min(test_dataset[0][0])} , {np.max(test_dataset[0][0])}]\")\n",
    "\n",
    "    try:\n",
    "        del multitask_model\n",
    "    except:\n",
    "        pass\n",
    "    tf.keras.backend.clear_session()\n",
    "    gc.collect()\n",
    "\n",
    "    multitask_model = create_model(backbone)\n",
    "\n",
    "    import os \n",
    "    try:\n",
    "        os.remove('/kaggle/working/multi_task_all.h5')\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    optim_zero = tf.keras.optimizers.Adam()\n",
    "    dice_loss = sm.losses.DiceLoss()\n",
    "    focal_loss = sm.losses.BinaryFocalLoss()\n",
    "    total_loss = dice_loss + (1 * focal_loss)\n",
    "    classification_loss = sm.losses.BinaryFocalLoss(alpha=0.6, gamma=2.0)\n",
    "    \n",
    "    metrics = {'classification_output': ['accuracy'], 'sigmoid': [sm.metrics.IOUScore(threshold=0.5)]}\n",
    "    loss_weights = {'classification_output': 1, 'sigmoid': 1}\n",
    "    loss = {'classification_output': classification_loss, 'sigmoid': total_loss}\n",
    "\n",
    "    multitask_model.compile(optim_zero, loss_weights=loss_weights, loss=loss, metrics=metrics)\n",
    "    \n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.ModelCheckpoint('./best_model.h5', save_weights_only=True, save_best_only=True, mode='min'),\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(),\n",
    "        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='min')\n",
    "    ]\n",
    "\n",
    "    history = multitask_model.fit(\n",
    "            train_dataloader,\n",
    "            steps_per_epoch=len(train_dataloader),\n",
    "            epochs=500,\n",
    "            validation_data=valid_dataloader,\n",
    "            validation_steps=len(valid_dataloader),\n",
    "            callbacks=callbacks\n",
    "    )\n",
    "    historys.append(history)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-18T00:37:41.624769Z",
     "iopub.status.busy": "2025-03-18T00:37:41.624412Z",
     "iopub.status.idle": "2025-03-18T00:37:42.986571Z",
     "shell.execute_reply": "2025-03-18T00:37:42.985580Z",
     "shell.execute_reply.started": "2025-03-18T00:37:41.624740Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "multitask_model.load_weights('/kaggle/working/best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-18T00:37:42.988164Z",
     "iopub.status.busy": "2025-03-18T00:37:42.987853Z",
     "iopub.status.idle": "2025-03-18T00:39:14.377855Z",
     "shell.execute_reply": "2025-03-18T00:39:14.377062Z",
     "shell.execute_reply.started": "2025-03-18T00:37:42.988141Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plot_some_images(multitask_model, test_dataset)\n",
    "print_test_metrics(multitask_model, test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 4945165,
     "sourceId": 9066720,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "video",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
